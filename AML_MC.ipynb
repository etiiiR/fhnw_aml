{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e674a206",
   "metadata": {},
   "source": [
    "title:  AML Challenge 2024\n",
    "date: \"Generated: {{ datetime.now().strftime('%Y-%m-%d') }}\"\n",
    "author: Etienne Roulet, Alexander Shanmugam\n",
    "output:\n",
    "    general:\n",
    "        input_jinja: true\n",
    "    html:\n",
    "        code_folding: hide\n",
    "        code_tools: true\n",
    "        theme: readable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c61a7a7",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Die folgenden Code-Blöcke können genutzt werden, um die benötigten Abhängigkeiten zu installieren und zu importieren."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install -r ../requirements.txt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3277c2cbdb507dd4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "%load_ext pretty_jupyter"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4276bc363ea5171"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Laden der eingesetzten Libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itables import init_notebook_mode\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import sweetviz as sv\n",
    "\n",
    "init_notebook_mode(all_interactive=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7434f24d53997b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Aufgabenstellung\n",
    "Inhalt der hier bearbeiteten und dokumentierten Mini-Challenge für das Modul «aml - Angewandtes Machine Learning» der FHNW ist die Entwicklung und Evaluierung von Aﬀinitätsmodellen für personalisierte Kreditkarten-Werbekampagnen im Auftrag einer Bank. Das Ziel der Authoren ist es also, mithilfe von Kunden- und Transaktionsdaten präzise Modelle zu erstellen, die die Wahrscheinlichkeit des Kreditkartenkaufs einer bestimmten Person vorhersagen."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d220994488768fa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from itables import init_notebook_mode\n",
    "from datetime import datetime\n",
    "from IPython.display import display\n",
    "import sweetviz as sv\n",
    "\n",
    "init_notebook_mode(all_interactive=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51fc06196d89c12e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Laden der zur Verfügung gestellten Daten\n",
    "[//]: # (-.- .tabset)\n",
    "\n",
    "Zur Verfügung gestellt wurden 8 csv-Dateien von welchen die Beschreibung der erfassten Variablen unter dem folgenden Link eingesehen werden können: [PKDD'99 Discovery Challenge - Guide to the Financial Data Set](https://sorry.vse.cz/~berka/challenge/PAST/index.html). Nachfolgend werden diese csv-Dateien eingelesen."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba2e8c08539a5adf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "account = pd.read_csv(\"account.csv\", sep=\";\", dtype={\"date\": \"str\"})\n",
    "card = pd.read_csv(\"card.csv\", sep=\";\", dtype={\"issued\": \"str\"})\n",
    "client = pd.read_csv(\"client.csv\", sep=\";\")\n",
    "disp = pd.read_csv(\"disp.csv\", sep=\";\")\n",
    "district = pd.read_csv(\"district.csv\", sep=\";\")\n",
    "loan = pd.read_csv(\"loan.csv\", sep=\";\", dtype={\"date\": \"str\"})\n",
    "order = pd.read_csv(\"order.csv\", sep=\";\")\n",
    "trans = pd.read_csv(\"trans.csv\", sep=\";\", dtype={\"date\": \"str\", \"bank\": \"str\"})"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6f5662a420662bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## account.csv\n",
    "Der Datensatz `accounts.csv` beinhaltet die folgenden Informationen über die Kontos der Bank:  \n",
    "- `account_id`: die Kontonummer, \n",
    "- `district_id`: den Standort der entsprechenden Bankfiliale,\n",
    "- `issuance_statement_frequency`: die Frequenz der Ausstellung von Kontoauszügen (monatlich, wöchentlich, pro Transaktion) und \n",
    "- `date`: das Erstellungsdatum"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4ce4318911e59a5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "account.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98e7b96ca758d87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## card.csv\n",
    "Der Datensatz `card.csv` beinhaltet die folgenden Informationen über die von der Bank herausgegebenen Kreditkarten:  \n",
    "- `card_id`: die Kartennummer, \n",
    "- `disp_id`: die Zuordnung zum entsprechenden Bankkonto und -inhaber (Disposition),\n",
    "- `type`: die Art der Kreditkarte (junior, classic, gold) und \n",
    "- `issued`: das Ausstellungsdatum"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5280910af497377"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "card.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d13e2ada8f3abe89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## client.csv\n",
    "Der Datensatz `client.csv` beinhaltet die folgenden Informationen über die Kunden der Bank:  \n",
    "- `client_id`: die Kundennummer, \n",
    "- `birth_number`: eine Kombination aus Geburtsdatum und Geschlecht sowie\n",
    "- `district_id`: die Adresse  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b53fab1a474c3c91"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "client.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5d89c25d6262ab9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## disp.csv\n",
    "Der Datensatz `disp.csv` beinhaltet die folgenden Informationen über die Dispositionen der Bank:  \n",
    "- `disp_id`: der Identifikationsschlüssel der Disposition,\n",
    "- `client_id`: die Kundennummer,\n",
    "- `account_id`: die Kontonummer,\n",
    "- `type`: die Art der Disposition (Inhaber, Benutzer)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c4a5c1f11e8162"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "disp.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bca2e0a093764c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## district.csv\n",
    "Der Datensatz `district.csv` beinhaltet die folgenden demografischen Informationen:  \n",
    "- `A1`: die ID des Distrikts, \n",
    "- `A2`: der Name des Distrikts,\n",
    "- `A3`: die Region,\n",
    "- `A4`: die Anzahl der Einwohner,\n",
    "- `A5`: die Anzahl der Gemeinden mit < 499 Einwohner,\n",
    "- `A6`: die Anzahl der Gemeinden mit 500 - 1999 Einwohner,\n",
    "- `A7`: die Anzahl der Gemeinden mit 2000 - 9999 Einwohner,\n",
    "- `A8`: die Anzahl der Gemeinden mit >10000 Einwohner,\n",
    "- `A9`: die Anzahl Städte,\n",
    "- `A10`: das Verhältnis von städtischen Einwohnern,\n",
    "- `A11`: das durchschnittliche Einkommen,\n",
    "- `A12`: die Arbeitslosenrate vom Jahr 95,\n",
    "- `A13`: die Arbeitslosenrate vom Jahr 96,\n",
    "- `A14`: die Anzahl von Unternehmer pro 1000 Einwohner,\n",
    "- `A15`: die Anzahl von begangenen Verbrechen im Jahr 95,\n",
    "- `A16`: die Anzahl von begangenen Verbrechen im Jahr 96,"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c8cf14c6f30770d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "district.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c136a51268f3174c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## loan.csv\n",
    "Der Datensatz `loan.csv` beinhaltet die folgenden Informationen über die vergebenen Darlehen der Bank:  \n",
    "- `loan_id`: ID des Darlehens,\n",
    "- `account_id`: die Kontonummer,\n",
    "- `date`: das Datum, wann das Darlehen gewährt wurde,\n",
    "- `amount`: der Betrag,\n",
    "- `duration`: die Dauer des Darlehens,\n",
    "- `payments`: die höhe der monatlichen Zahlungen und\n",
    "- `status`: der Rückzahlungsstatus (A: ausgeglichen, B: Vertrag abgelaufen aber nicht fertig bezahlt, C: laufender Vertrag und alles in Ordnung, D: laufender Vertrag und Kunde verschuldet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a91e45660ff160a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loan.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd2310aac3b708fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## order.csv\n",
    "Der Datensatz `order.csv` beinhaltet die folgenden Informationen über die Daueraufträge eines Kontos:  \n",
    "- `order_id`: die Nummer des Dauerauftrags,\n",
    "- `account_id`: die Kontonummer von welchem der Auftrag stammt,\n",
    "- `bank_to`: die empfangende Bank,\n",
    "- `account_to`: das empfangende Konto, \n",
    "- `amount`: der Betrag,\n",
    "- `k_symbol`: die Art des Auftrags (Versicherungszahlung, Haushalt, Leasing, Darlehen)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd11e14b3a50223c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "order.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "690af57fa8d4d874"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## trans.csv\n",
    "Der Datensatz `trans.csv` beinhaltet die folgenden Informationen über die Transaktionen eines Kontos:  \n",
    "- `trans_id`: die ID der Transaktion,\n",
    "- `account_id`: die Kontonummer des ausführenden Kontos,\n",
    "- `date`: das Datum,\n",
    "- `type`: der Typ (Einzahlung, Bezug)\n",
    "- `operation`: die Art der Transaktion (Bezug Kreditkarte, Bareinzahlung, Bezug über eine andere Bank, Bezug Bar, Überweisung)\n",
    "- `amount`: der Betrag der Transaktion,\n",
    "- `balance`: der Kontostand nach ausführung der Transaktion,\n",
    "- `k_symbol`: die Klassifikation der Transaktion (Versicherungszahlung, Kontoauszug, Zinsauszahlung, Zinszahlung bei negativem Kontostand, Haushalt, Pension, Darlehensauszahlung),\n",
    "- `bank`: die empfangende Bank und \n",
    "- `account`: das empfangende Bankkonto"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdf9440e260c3d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trans.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa36c789c5d7655a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformationen \n",
    "[//]: # (-.- .tabset)\n",
    "\n",
    "Im folgenden Abschnitt werden die geladenen Daten separat so transformiert, dass jede Zeile einer Observation und jede Spalte einer Variable im entsprechenden Datenformat entspricht, also ins Tidy-Format gebracht."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef8f29a3466673ca"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_frames = {}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b38748605e9503d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Account"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c098a82cd43e8ec6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "account[\"date\"] = pd.to_datetime(account[\"date\"], format=\"%y%m%d\")\n",
    "# Frequency Transformation\n",
    "account[\"frequency\"] = account[\"frequency\"].replace(\n",
    "    {\n",
    "        \"POPLATEK MESICNE\": \"monthly issuance\",\n",
    "        \"POPLATEK TYDNE\": \"weekly issuance\",\n",
    "        \"POPLATEK PO OBRATU\": \"issuance after transaction\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rename Column\n",
    "account = account.rename(columns={\"frequency\": \"issuance_statement_frequency\"})\n",
    "\n",
    "# Convert Date Column to datetime format\n",
    "account[\"date\"] = pd.to_datetime(account[\"date\"])\n",
    "\n",
    "# Assuming 'data_frames' is a dictionary of DataFrames\n",
    "data_frames[\"account.csv\"] = account\n",
    "\n",
    "# Sample 5 random rows\n",
    "account.sample(n=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1572baa20ae3a77d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "svReport_account = sv.analyze(account)\n",
    "svReport_account.show_html(filepath = \"./reports/accounts.html\", open_browser = False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ab234ff77c967c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Card"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "477e55adf2106617"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Man kann die Zeit weglassen da immer 00:00:00\n",
    "card[\"issued\"] = pd.to_datetime(card[\"issued\"].str[:6], format=\"%y%m%d\")\n",
    "card[\"issued\"] = pd.to_datetime(card[\"issued\"], format=\"mixed\")\n",
    "data_frames[\"card.csv\"] = card"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b15e9ed8a3043be"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "svReport_card = sv.analyze(card)\n",
    "svReport_card.show_html(filepath = \"./reports/card.html\", open_browser = False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6822e47f34d9b36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Client"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae117e88d9e457d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Funktion zur Bestimmung des Geschlechts und Berechnung des Geburtstags\n",
    "def parse_details(birth_number):\n",
    "    birth_number_str = str(\n",
    "        birth_number\n",
    "    )  # Konvertiere birth_number zu einem String, falls notwendig\n",
    "    year_prefix = \"19\"\n",
    "    month = int(birth_number_str[2:4])\n",
    "    gender = \"female\" if month > 12 else \"male\"\n",
    "    if gender == \"female\":\n",
    "        month -= 50\n",
    "    year = int(year_prefix + birth_number_str[:2])\n",
    "    day = int(birth_number_str[4:6])\n",
    "    birth_day = datetime(year, month, day)\n",
    "    return gender, birth_day\n",
    "\n",
    "\n",
    "# Berechnung des Alters basierend auf einem Basisjahr\n",
    "def calculate_age(birth_date, base_date=datetime(1999, 12, 31)):\n",
    "    return (\n",
    "        base_date.year\n",
    "        - birth_date.year\n",
    "        - ((base_date.month, base_date.day) < (birth_date.month, birth_date.day))\n",
    "    )\n",
    "\n",
    "\n",
    "# Anwenden der Funktionen und Erstellen neuer Spalten\n",
    "client[\"gender\"], client[\"birth_day\"] = zip(\n",
    "    *client[\"birth_number\"].apply(parse_details)\n",
    ")\n",
    "client[\"age\"] = client[\"birth_day\"].apply(calculate_age)\n",
    "\n",
    "data_frames[\"client.csv\"] = client\n",
    "\n",
    "# Auswahl spezifischer Spalten für die finale DataFrame (optional, je nach Bedarf)\n",
    "# Sample 5 random rows\n",
    "client.sample(n=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93d15b815b001ed2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "svReport_client = sv.analyze(client)\n",
    "svReport_client.show_html(filepath = \"./reports/client.html\", open_browser = False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22b7f6addb732287"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Disp"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2bb3412e47380275"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_frames[\"disp.csv\"] = disp\n",
    "\n",
    "# random sample\n",
    "disp.sample(n=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0a31ca097a8791a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "svReport_disp = sv.analyze(disp)\n",
    "svReport_disp.show_html(filepath = \"./reports/disp.html\", open_browser = False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4d5ed056b40df66"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## District\n",
    "\n",
    "\n",
    "- A1 district_id/district code\n",
    "- A2 district name\n",
    "- A3 region\n",
    "- A4 no. of inhabitants\n",
    "- A5 no. of municipalities with inhabitants < 499\n",
    "- A6 no. of municipalities with inhabitants 500-1999 A7 no. of municipalities with inhabitants 2000-9999\n",
    "- A8 no. of municipalities with inhabitants >10000\n",
    "- A9 no. of cities\n",
    "- A10 ratio of urban inhabitants\n",
    "- A11 average salary\n",
    "- A12 unemploymant rate ’95\n",
    "- A13 unemploymant rate ’96\n",
    "- A14 no. of enterpreneurs per 1000 inhabitants\n",
    "- A15 no. of commited crimes ’95\n",
    "- A16 no. of commited crimes ’96"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "561584fefb112ecf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Renaming and selecting columns\n",
    "district = district.rename(\n",
    "    columns={\n",
    "        \"A1\": \"district_id\",\n",
    "        \"A2\": \"district_name\",\n",
    "        \"A3\": \"region\",\n",
    "        \"A4\": \"num_of_habitat\",\n",
    "        \"A5\": \"num_of_small_town\",\n",
    "        \"A6\": \"num_of_medium_town\",\n",
    "        \"A7\": \"num_of_big_town\",\n",
    "        \"A8\": \"num_of_bigger_town\",\n",
    "        \"A9\": \"num_of_city\",\n",
    "        \"A10\": \"ratio_of_urban\",\n",
    "        \"A11\": \"average_salary\",\n",
    "        \"A12\": \"unemploy_rate95\",\n",
    "        \"A13\": \"unemploy_rate96\",\n",
    "        \"A14\": \"n_of_enterpren_per1000_inhabit\",\n",
    "        \"A15\": \"no_of_crimes95\",\n",
    "        \"A16\": \"no_of_crimes96\",\n",
    "    }\n",
    ")[\n",
    "    [\n",
    "        \"district_id\",\n",
    "        \"district_name\",\n",
    "        \"region\",\n",
    "        \"num_of_habitat\",\n",
    "        \"num_of_small_town\",\n",
    "        \"num_of_medium_town\",\n",
    "        \"num_of_big_town\",\n",
    "        \"num_of_bigger_town\",\n",
    "        \"num_of_city\",\n",
    "        \"ratio_of_urban\",\n",
    "        \"average_salary\",\n",
    "        \"unemploy_rate95\",\n",
    "        \"unemploy_rate96\",\n",
    "        \"n_of_enterpren_per1000_inhabit\",\n",
    "        \"no_of_crimes95\",\n",
    "        \"no_of_crimes96\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "data_frames[\"district.csv\"] = district\n",
    "\n",
    "district.sample(n=5)\n",
    "district"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca5eb781dfa402b0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# find the ? in the district dataframe\n",
    "district[district.isin([\"?\"]).any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d573a24e2ff266b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# replace the ? with NaN\n",
    "district = district.replace(\"?\", np.nan)\n",
    "\n",
    "# replace the NaN with the mean of the column no_of_crimes95 and unemploy_rate95\n",
    "district[\"no_of_crimes95\"] = district[\"no_of_crimes95\"].astype(float)\n",
    "district[\"unemploy_rate95\"] = district[\"unemploy_rate95\"].astype(float)\n",
    "district[\"no_of_crimes95\"] = district[\"no_of_crimes95\"].fillna(\n",
    "    district[\"no_of_crimes95\"].mean()\n",
    ")\n",
    "district[\"unemploy_rate95\"] = district[\"unemploy_rate95\"].fillna(\n",
    "    district[\"unemploy_rate95\"].mean()\n",
    ")\n",
    "# check if there are still NaN values in no_of_crimes95 and unemploy_rate95\n",
    "district[district.isin([np.nan]).any(axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a061821a0a0b6e2f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "svReport_district = sv.analyze(district)\n",
    "svReport_district.show_html(filepath = \"./reports/district.html\", open_browser = False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cb0bea704c5cd3c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loan"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be613d353bef8689"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loan[\"date\"] = pd.to_datetime(loan[\"date\"], format=\"%y%m%d\")\n",
    "# Convert the 'date' column to datetime format\n",
    "loan[\"date\"] = pd.to_datetime(loan[\"date\"], format=\"mixed\")\n",
    "\n",
    "# Mutate the 'status' column based on conditions\n",
    "loan[\"status\"] = loan[\"status\"].map(\n",
    "    {\n",
    "        \"A\": \"contract finished\",\n",
    "        \"B\": \"finished contract, loan not paid\",\n",
    "        \"C\": \"running contract\",\n",
    "        \"D\": \"client in debt\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Group by 'account_id', calculate the number of loans, and sort the results\n",
    "num_of_loan_df = (\n",
    "    loan.groupby(\"account_id\")\n",
    "    .size()\n",
    "    .reset_index(name=\"num_of_loan\")\n",
    "    .sort_values(by=\"num_of_loan\", ascending=False)\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "num_of_loan_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9daf22b0a1354442"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Perform an inner join between 'loan' and 'num_of_loan_df' on 'account_id'\n",
    "loan = pd.merge(loan, num_of_loan_df, on=\"account_id\", how=\"inner\")\n",
    "\n",
    "# Assign the resulting DataFrame to a dictionary for storage\n",
    "data_frames[\"loan.csv\"] = loan\n",
    "\n",
    "# Sample 5 random rows from the joined DataFrame\n",
    "loan.sample(n=100)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5856fbdd901c0431"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "svReport_loan = sv.analyze(loan)\n",
    "svReport_loan.show_html(filepath = \"./reports/loan.html\", open_browser = False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "756c1c351adb9047"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Order\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7db50ce93185c8f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "order"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43015f09e760b5b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Assuming 'order' and 'account' DataFrames are already loaded\n",
    "\n",
    "# Correctly map and fill missing values in 'k_symbol' column\n",
    "order[\"k_symbol\"] = (\n",
    "    order[\"k_symbol\"]\n",
    "    .map(\n",
    "        {\n",
    "            \"POJISTNE\": \"insurance_payment\",\n",
    "            \"SIPO\": \"household\",\n",
    "            \"UVER\": \"loan_payment\",\n",
    "            \"LEASING\": \"leasing\",\n",
    "        }\n",
    "    )\n",
    "    .fillna(\"unknown\")\n",
    ")\n",
    "\n",
    "# Merge with 'account_id_df' to ensure all accounts are represented\n",
    "order = pd.merge(account[[\"account_id\"]], order, on=\"account_id\", how=\"left\")\n",
    "\n",
    "# After merging, fill missing values that may have been introduced\n",
    "order[\"k_symbol\"] = order[\"k_symbol\"].fillna(\"unknown\")\n",
    "order[\"amount\"] = order[\"amount\"].fillna(0)\n",
    "order[\"has_order\"] = ~order.isna().any(axis=1)\n",
    "\n",
    "orders_pivot = order.pivot_table(\n",
    "    index=\"account_id\", columns=\"k_symbol\", values=\"amount\", aggfunc=\"sum\"\n",
    ")\n",
    "\n",
    "# Add prefix to column names\n",
    "orders_pivot.columns = orders_pivot.columns\n",
    "\n",
    "\n",
    "orders_pivot = orders_pivot.reset_index()\n",
    "# Assuming data_frames is a dictionary for storing DataFrames\n",
    "data_frames[\"order.csv\"] = orders_pivot\n",
    "\n",
    "# NaN to 0\n",
    "data_frames[\"order.csv\"] = data_frames[\"order.csv\"].fillna(0)\n",
    "# Sample 5 random rows from the merged DataFrame\n",
    "data_frames[\"order.csv\"].sample(n=10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef2ebca6c205009a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_frames[\"order.csv\"].columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a79f625d32a721ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "svReport_order = sv.analyze(order)\n",
    "svReport_order.show_html(filepath = \"./reports/order.html\", open_browser = False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89267bb7d9194c9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trans\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db081e6effcd030d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trans[\"date\"] = pd.to_datetime(trans[\"date\"], format=\"%y%m%d\")\n",
    "# Convert 'date' from string to datetime\n",
    "trans[\"date\"] = pd.to_datetime(trans[\"date\"])\n",
    "\n",
    "# Update 'type' column\n",
    "trans[\"type\"] = trans[\"type\"].replace({\"PRIJEM\": \"credit\", \"VYDAJ\": \"withdrawal\"})\n",
    "\n",
    "# Update 'operation' column\n",
    "trans[\"operation\"] = trans[\"operation\"].replace(\n",
    "    {\n",
    "        \"VYBER KARTOU\": \"credit card withdrawal\",\n",
    "        \"VKLAD\": \"credit in cash\",\n",
    "        \"PREVOD Z UCTU\": \"collection from another bank\",\n",
    "        \"VYBER\": \"cash withdrawal\",\n",
    "        \"PREVOD NA UCET\": \"remittance to another bank\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Update 'k_symbol' column\n",
    "trans[\"k_symbol\"] = trans[\"k_symbol\"].replace(\n",
    "    {\n",
    "        \"POJISTNE\": \"insurance payment\",\n",
    "        \"SLUZBY\": \"statement payment\",\n",
    "        \"UROK\": \"interest credited\",\n",
    "        \"SANKC. UROK\": \"sanction interest if negative balance\",\n",
    "        \"SIPO\": \"household payment\",\n",
    "        \"DUCHOD\": \"pension credited\",\n",
    "        \"UVER\": \"loan payment\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# negate the amount if type is credit\n",
    "trans.loc[trans['type'] == 'credit', 'amount'] = trans.loc[trans['type'] == 'credit', 'amount'] * (-1)\n",
    "\n",
    "# Assign to a dictionary if needed (similar to list assignment in R)\n",
    "\n",
    "data_frames[\"trans.csv\"] = trans\n",
    "\n",
    "# Sample 5 random rows from the DataFrame\n",
    "trans.sample(n=1000)\n",
    "trans"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1977722f96cbe523"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot Zeitliche Entwicklung des Konto-Saldos für die Konto nummer 19\n",
    "account_19 = trans[trans[\"account_id\"] == 19].copy()  # Create a copy of the DataFrame\n",
    "# Ensure the date column is in datetime format\n",
    "account_19[\"date\"] = pd.to_datetime(account_19[\"date\"])\n",
    "\n",
    "# Sort the values by date\n",
    "account_19 = account_19.sort_values(\"date\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(account_19[\"date\"], account_19[\"balance\"])\n",
    "plt.title(\"Time evolution of balance for account number 19\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Balance\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5aff28ea2dc926a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# zoom the year 1995 of the plot\n",
    "account_19_1995 = account_19[account_19[\"date\"].dt.year == 1995]\n",
    "# plot it\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(account_19_1995[\"date\"], account_19_1995[\"balance\"])\n",
    "plt.title(\"Time evolution of balance for account number 19 in 1995\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Balance\")\n",
    "plt.show()\n",
    "\n",
    "# Wee see that there is a steep line in 1995-10 so there are two transactions, this we have to clean."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44de709820489a92"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%%capture\n",
    "svReport_trans = sv.analyze(trans)\n",
    "svReport_trans.show_html(filepath = \"./reports/trans.html\", open_browser = False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "321fc59606057103"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explorative Datenanalyse\n",
    "In diesem Abschnitt wird mittels EDA ein Überblick über die eingelesenen Daten gewonnen."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6b5879759a91d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# D&Q"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf48517f8b9d365f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check for missing values in each DataFrame\n",
    "for df_name, df in data_frames.items():\n",
    "    print(f\"Missing values in {df_name}:\")\n",
    "    print(df.isna().sum().sum())  # Sum of all missing values in the DataFrame"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "43bdd6c61548214d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Merge the Dataframe['XXX'] for non transaction Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c4dfec052fdc20f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# merge dataframes\n",
    "\n",
    "non_transactional_data = (\n",
    "    data_frames[\"disp.csv\"]\n",
    "    .add_suffix(\"_disp\")\n",
    "    .merge(\n",
    "        data_frames[\"account.csv\"].add_suffix(\"_account\"),\n",
    "        left_on=\"account_id_disp\",\n",
    "        right_on=\"account_id_account\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        data_frames[\"card.csv\"].add_suffix(\"_card\"),\n",
    "        left_on=\"disp_id_disp\",\n",
    "        right_on=\"disp_id_card\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        data_frames[\"loan.csv\"].add_suffix(\"_loan\"),\n",
    "        left_on=\"account_id_disp\",\n",
    "        right_on=\"account_id_loan\",\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .merge(\n",
    "        data_frames[\"order.csv\"].add_suffix(\"_order\"),\n",
    "        left_on=\"account_id_disp\",\n",
    "        right_on=\"account_id_order\",\n",
    "        how=\"left\",\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "698ec91f4d89feb8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "non_transactional_data.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63cb3baf197c1351"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cols_to_replace_na = [\n",
    "    \"household_order\",\n",
    "    \"insurance_payment_order\",\n",
    "    \"loan_payment_order\",\n",
    "    \"leasing_order\",\n",
    "    \"unknown_order\",\n",
    "]\n",
    "\n",
    "non_transactional_data[cols_to_replace_na] = non_transactional_data[\n",
    "    cols_to_replace_na\n",
    "].fillna(0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef6cc82d2aa4cc84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dropping of Junior Cards that are not on the edge to a normal card Analyse\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4113c0294933029"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# join district and client left join on district_id\n",
    "non_transactional_data = non_transactional_data.merge(\n",
    "    data_frames[\"district.csv\"],\n",
    "    left_on=\"district_id_account\",\n",
    "    right_on=\"district_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "non_transactional_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a182f9fc63a2aca"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# merge client with suffix\n",
    "non_transactional_data = non_transactional_data.merge(\n",
    "    data_frames[\"client.csv\"].add_suffix(\"_client\"),\n",
    "    left_on=\"client_id_disp\",\n",
    "    right_on=\"client_id_client\",\n",
    "    how=\"left\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dd07d1f2241d406"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "non_transactional_data[\"has_card\"] = ~non_transactional_data[\"card_id_card\"].isna()\n",
    "\n",
    "# Filter rows where 'has_card' is True\n",
    "filtered_data = non_transactional_data[non_transactional_data[\"has_card\"]]\n",
    "\n",
    "# Check if there are duplicated 'account_id' in the filtered data\n",
    "duplicated_account_id = filtered_data[\"account_id_account\"].duplicated().sum()\n",
    "\n",
    "print(duplicated_account_id)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20f18b81a9f52b84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Junior Cards removal"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e87290aaef4bff76"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "display(non_transactional_data)\n",
    "\n",
    "# Filter rows where 'card_type' contains 'junior' (case insensitive)\n",
    "junior_cards = non_transactional_data[\n",
    "    non_transactional_data[\"type_card\"].str.contains(\"junior\", case=False, na=False)\n",
    "]\n",
    "\n",
    "display(junior_cards)\n",
    "\n",
    "# Calculate age at issue\n",
    "junior_cards[\"age_at_issue\"] = (\n",
    "    junior_cards[\"issued_card\"] - junior_cards[\"birth_day_client\"]\n",
    ").dt.days // 365\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=junior_cards, x=\"age_at_issue\", bins=20)\n",
    "plt.title(\"Age distribution at issue date of junior cards\")\n",
    "plt.xlabel(\"Age at issue date\")\n",
    "plt.ylabel(\"Number of cards\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63c3860efd8fa236"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the advertising campaign, we do not want to promote children's/junior cards (for whatever reasons). First, I looked at the distribution of age at issuance. Here I see that there are not many junior cards, nor are the cards issued at a late age."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cabfefd14090501"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_accounts_before = len(non_transactional_data)\n",
    "# Filter rows where 'card_type' does not contain 'junior' (case insensitive)\n",
    "non_transactional_data = non_transactional_data[\n",
    "    ~non_transactional_data[\"type_card\"].str.contains(\"junior\", case=False, na=False)\n",
    "]\n",
    "num_accounts_after = len(non_transactional_data)\n",
    "num_junior_cards = num_accounts_before - num_accounts_after\n",
    "print(f\"Number of junior cards removed: {num_junior_cards}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bf510609a371fd0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert the Notebook always to a py file and vice versa"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ffa05bf38aad58b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pathlib\n",
    "\n",
    "\n",
    "try:\n",
    "    file_path = pathlib.Path(os.path.basename(__file__))\n",
    "except:\n",
    "    file_path = pathlib.Path(\"AML_MC.ipynb\")\n",
    "\n",
    "# Check the file extension\n",
    "if file_path.suffix == \".py\":\n",
    "    # If it's a Python script, convert it to a notebook\n",
    "    try:\n",
    "        subprocess.check_output([\"jupytext\", \"--to\", \"notebook\", str(file_path)])\n",
    "        print(\"Converted to notebook.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Conversion failed. Error message:\", e.output)\n",
    "elif file_path.suffix == \".ipynb\":\n",
    "    # If it's a notebook, convert it to a Python script with cell markers\n",
    "    try:\n",
    "        subprocess.check_output([\"jupytext\", \"--to\", \"py:percent\", str(file_path)])\n",
    "        print(\"Converted to Python script.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Conversion failed. Error message:\", e.output)\n",
    "else:\n",
    "    print(\"Unsupported file type.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "662acb3a043ef7cb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Update html output\n",
    "os.system(\"jupyter nbconvert --to html --template pj AML_MC.ipynb\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f3bbd431ec27977"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c8e5f9ce6ebb1561"
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
